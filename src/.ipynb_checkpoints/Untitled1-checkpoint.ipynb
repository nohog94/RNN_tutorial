{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63ed246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import math\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "10e69c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
    "    \"\"\"Train a net within one epoch (defined in Chapter 8).\"\"\"\n",
    "    state, timer = None, d2l.Timer()\n",
    "    metric = d2l.Accumulator(2)  # Sum of training loss, no. of tokens\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # Initialize `state` when either it is the first iteration or\n",
    "            # using random sampling\n",
    "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
    "\n",
    "        else:\n",
    "            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
    "                # `state` is a tensor for `nn.GRU`\n",
    "                state.detach_()\n",
    "            else:\n",
    "                # `state` is a tuple of tensors for `nn.LSTM` and\n",
    "                # for our custom scratch implementation\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        print(X.requires_grad)\n",
    "        y = Y.T.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, state)\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            # Since the `mean` function has been invoked\n",
    "            updater(batch_size=1)\n",
    "        metric.add(l * d2l.size(y), d2l.size(y))\n",
    "    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "073df97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, num_hiddens, device = len(vocab), 256, d2l.try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59351301",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = vocab_size\n",
    "lstm_layer = nn.LSTM(num_inputs, num_hiddens)\n",
    "net = d2l.RNNModel(lstm_layer, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56b2ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, lr = 500, 1\n",
    "loss = nn.CrossEntropyLoss()\n",
    "updater = torch.optim.SGD(net.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11cb1573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(net, theta):\n",
    "    \"\"\"Clip the gradient.\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad**2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7535dd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "ppl, speed = train_epoch_ch8(net, train_iter, loss, updater, device, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ec3a8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ch8(prefix, num_preds, net, vocab, device):\n",
    "    \"\"\"Generate new characters following the `prefix`.\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: d2l.reshape(d2l.tensor([outputs[-1]], device=device),\n",
    "                                    (1, 1))\n",
    "    for y in prefix[1:]:  # Warm-up period\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # Predict `num_preds` steps\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    print(state[0].size())\n",
    "    print(get_input().size())\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "df0cc608",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "30febae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'time traveller'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6551575d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[prefix[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "908a390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fbc1ed4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256])\n",
      "torch.Size([1, 1])\n",
      "time traveller te te te te te te te te te te te te te te te te t\n"
     ]
    }
   ],
   "source": [
    "print(predict('time traveller'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNN_tutorial",
   "language": "python",
   "name": "rnn_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
